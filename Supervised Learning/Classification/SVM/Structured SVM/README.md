# ü§ñ What is Structured Support Vector Machine (Structured SVM)?

**Structured SVM** is an extension of Support Vector Machines designed for **structured output spaces**, where the prediction is not a single label but a complex structure like **sequences, trees, or graphs**.

Examples include:
- Part-of-Speech (POS) tagging (sequence)
- Image segmentation (grid/graph)
- Named Entity Recognition (NER)
- Dependency parsing (tree)

---

## üõ†Ô∏è How to Use Structured SVM

1. **Install pystruct (Python)**  
   ~ Run: `pip install pystruct`

2. **Prepare Structured Data**  
   ~ Each training example should consist of:
     - Input: sequence or structure of feature vectors
     - Output: corresponding structured labels (e.g., sequences)

3. **Choose a Model**  
   ~ Common models in `pystruct`:
     - `ChainCRF` for sequences
     - `GridCRF` for 2D grid (e.g., images)

4. **Train the Structured SVM**  
   ~ Fit the model using `StructuredSVM` or `NSlackSSVM`:
   ```python
   from pystruct.models import ChainCRF
   from pystruct.learners import StructuredSVM

   model = ChainCRF()
   ssvm = StructuredSVM(model=model, C=1.0)
   ssvm.fit(X_train, Y_train)
   ```

5. **Make Predictions**  
   ~ Use `predict()` to label new inputs.

6. **Evaluate Performance**  
   ~ Use sequence or structured accuracy, Hamming loss, etc.

---

## ‚ùì Why Do We Use Structured SVM

1. **Handles Complex Outputs**  
   ~ Useful when outputs are interdependent (e.g., words in a sentence).

2. **Better Accuracy for Structured Tasks**  
   ~ Leverages dependencies between output labels.

3. **Theoretical Guarantees**  
   ~ Maintains large-margin principles from classic SVMs.

4. **Extendable Framework**  
   ~ Can incorporate domain-specific structures with custom models.

5. **Widely Used in NLP and Vision**  
   ~ Structured SVMs are ideal for sequence and image labeling tasks.

---

## ‚öôÔ∏è How Does Structured SVM Work?

1. **Structured Output Modeling**  
   ~ Predicts complex outputs like label sequences, not individual labels.

2. **Large-Margin Formulation**  
   ~ Generalizes standard SVM margin to structured outputs.

3. **Inference-Based Training**  
   ~ Requires an inference algorithm (e.g., Viterbi, max-product) during training and prediction.

4. **Loss-Augmented Inference**  
   ~ Adds task-specific loss to ensure errors are penalized more.

5. **Convex Optimization**  
   ~ Solves quadratic programs using cutting-plane or subgradient methods.

---
