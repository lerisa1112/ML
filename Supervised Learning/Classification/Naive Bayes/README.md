🤖 What is Naive Bayes?
Naive Bayes is a type of Supervised Learning algorithm based on Bayes' Theorem, used mainly for classification tasks.
It assumes that all features are independent of each other — that’s why it’s called “naive.”

📚 Think of it like this:
If you know someone likes action movies and popcorn, Naive Bayes assumes their love for action movies and popcorn are unrelated — even if they aren’t in real life.


🛠️ How to Use Naive Bayes?
Collect Labeled Data
~ Data where each input is labeled with its correct category
📄 Example: Emails labeled as Spam or Not Spam

Preprocess the Data
~ Clean and transform into numerical format
🧹 Example: Convert text to word frequencies using Bag of Words or TF-IDF

Split the Dataset
~ Divide into training and testing parts
📊 80% training, 20% testing is common

Train the Naive Bayes Model
~ Learn probabilities of features given each class
📈 Uses Bayes’ Theorem to calculate class probabilities

Make Predictions
~ Given a new input, calculate which class is most probable

Evaluate Performance
~ Use metrics like:
✅ Accuracy
⚖️ Precision & Recall
🧮 Confusion Matrix


❓ Why Do We Use Naive Bayes?
⚡ Very Fast & Efficient
~ Perfect for large datasets or real-time applications

📬 Great for Text Classification
~ Used in Spam Detection, Sentiment Analysis, News Categorization

🧠 Performs Well on Small Datasets
~ Even with limited data, it can be very accurate

🛠️ Easy to Implement
~ Simple math, less tuning, and high interpretability


⚙️ How Does Naive Bayes Work?

![nv](https://github.com/user-attachments/assets/6990100f-baee-4437-8461-931f19aa1f6d)

